{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_file= pd.read_csv('poker-hand-testing.data')\n",
    "teste_file =pd.read_csv('poker-hand-training.data')\n",
    "\n",
    "test_file=teste_file.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0=training_file[training_file[\"CLASS\"]==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=training_file[training_file[\"CLASS\"]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=training_file[training_file[\"CLASS\"]==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=training_file[training_file[\"CLASS\"]==3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4=training_file[training_file[\"CLASS\"]==4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5=training_file[training_file[\"CLASS\"]==5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6=training_file[training_file[\"CLASS\"]==6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7=training_file[training_file[\"CLASS\"]==7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df8=training_file[training_file[\"CLASS\"]==8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df9=training_file[training_file[\"CLASS\"]==9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumarizado={}\n",
    "df0list=df0.values.tolist()\n",
    "sumarizado[0]=df0list\n",
    "df1list=df1.values.tolist()\n",
    "sumarizado[1]=df1list\n",
    "df2list=df2.values.tolist()\n",
    "sumarizado[2]=df2list\n",
    "df3list=df3.values.tolist()\n",
    "sumarizado[3]=df3list\n",
    "df4list=df4.values.tolist()\n",
    "sumarizado[4]=df4list\n",
    "df5list=df5.values.tolist()\n",
    "sumarizado[5]=df5list\n",
    "df6list=df6.values.tolist()\n",
    "sumarizado[6]=df6list\n",
    "df7list=df7.values.tolist()\n",
    "sumarizado[7]=df7list\n",
    "df8list=df8.values.tolist()\n",
    "sumarizado[8]=df8list\n",
    "df9list=df9.values.tolist()\n",
    "sumarizado[9]=df9list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(numbers):\n",
    "    return sum(numbers)/float(len(numbers))\n",
    " #Desvio padrÃ£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stdev(numbers): \n",
    "\tavg = mean(numbers)\n",
    "\tvariance = sum([pow(x-avg,2) for x in numbers])/float(len(numbers)-1)\n",
    "\treturn math.sqrt(variance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(dataset):\n",
    "   \n",
    "    summaries = [(mean(attribute), stdev(attribute)) for attribute in zip(*dataset)]\n",
    "    del summaries[-1]\n",
    "  \n",
    "    return summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarizeByClass(dataset):\n",
    "\tseparated = dataset\n",
    "\tsummaries = {}\n",
    "\tfor classValue, instances in separated.items():\n",
    "\t\tsummaries[classValue] = summarize(instances)\n",
    "\t\n",
    "\t\n",
    "\treturn summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateProbability(x, mean, stdev):\n",
    "\texponent = math.exp(-(math.pow(x-mean,2)/(2*math.pow(stdev,2))))\n",
    "\treturn (1 / (math.sqrt(2*math.pi) * stdev)) * exponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateClassProbabilities(summaries, inputVector):\n",
    "    probabilities = {}\n",
    "    for classValue, classSummaries in summaries.items():\n",
    "        chance= 1\n",
    "        for i in range(len(classSummaries)):\n",
    "            \n",
    "            mean, stdev = classSummaries[i]\n",
    "            x = inputVector[i]\n",
    "            chance *= calculateProbability(x, mean, stdev)\n",
    "        \n",
    "            chance=np.log(chance)\n",
    "        probabilities[classValue] =chance\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(summaries, inputVector):\n",
    "\tprobabilities = calculateClassProbabilities(summaries, inputVector)\n",
    "\tbestLabel, bestProb = None, -1\n",
    "\tfor classValue, probability in probabilities.items():\n",
    "\t\tif bestLabel is None or probability > bestProb:\n",
    "\t\t\tbestProb = probability\n",
    "\t\t\tbestLabel = classValue\n",
    "\t\n",
    "\treturn bestLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPredictions(summaries, testSet):\n",
    "\tpredictions = []\n",
    "\tfor i in range(len(testSet)):\n",
    "\t\tresult = predict(summaries, testSet[i])\n",
    "\t\tpredictions.append(result)\n",
    "\treturn predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAccuracy(testSet, predictions):\n",
    "    correct = 0\n",
    "    valorA=0\n",
    "    valorB=0\n",
    "    status=-1\n",
    "    situacao=-1\n",
    "    for i in range(len(testSet)):\n",
    "        if testSet[i][-1] == predictions[i]:\n",
    "            correct+=1\n",
    "    print(correct,\"\\n\")\n",
    "\t#Buscando qual a classe teve o maior acerto, acredito que estou no caminho certo, agora e fazer o teste final \n",
    "    accuracy=(correct/float(len(testSet)))\n",
    "    # * 100.0\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1025010 rows into train=1000000 and test=25010 rows\n",
      "C:\\Program Files\\Python37\\lib\\site-packages\\ipykernel_launcher.py:11: RuntimeWarning: invalid value encountered in log\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "12493 \n",
      "\n",
      "Accuracy: 0.4995201919232307%\n",
      "<class 'list'>\n",
      "0    25010\n",
      "Name: CLASS, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "# \tfilename = 'diabetes.csv'\n",
    "# \tsplitRatio = 0.67\n",
    "# \tstatus=-1\n",
    "# \tsituacao=-1\n",
    "    dataset = training_file\n",
    "# \ttrainingSet, testSet = splitDataset(dataset, splitRatio)\n",
    "    print('Split {0} rows into train={1} and test={2} rows'.format(len(training_file)+len(test_file), len(training_file), len(test_file)))\n",
    "    #prepare model\n",
    "    summaries = summarizeByClass(sumarizado)\n",
    "    # test model\n",
    "    predictions = getPredictions(summaries, test_file)\n",
    "    accuracy= getAccuracy(test_file, predictions)\n",
    "    print('Accuracy: {0}%'.format(accuracy))\n",
    "    # print(type(predictions))\n",
    "    # df =pd.DataFrame(predictions,columns =['CLASS'])\n",
    "    # sc=df['CLASS'].value_counts()\n",
    "    # print(sc)\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
